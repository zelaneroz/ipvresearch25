{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multilabel IPV Prediction Generation with Qwen\n",
        "\n",
        "This notebook generates multilabel predictions for IPV classification using Qwen model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n",
        "\n",
        "Edit the settings below before running the notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========== CONFIGURATION - EDIT THESE SETTINGS ==========\n",
        "\n",
        "# Prompt template (use {text} for sentence and {sample_id} for ID)\n",
        "PROMPT_TEMPLATE = \"\"\"\n",
        "You are identifying which forms of Intimate Partner Violence (IPV) appear in a sentence.\n",
        "\n",
        "Decide independently for emotional, physical, and sexual abuse. If it is a particular type of IPV, set emotional, physical, or sexual to 1, otherwise set it to 0. Multiple IPV types can be true or none at all.\n",
        "\n",
        "Return ONLY one JSON object enclosed between <json> and </json> with the keys 'id', 'emotional', 'physical', and 'sexual'.\n",
        "\n",
        "Sentence: \"{text}\"\n",
        "Sample ID: \"{sample_id}\"\n",
        "\n",
        "<json>\n",
        "{{\n",
        "  \"id\": \"{sample_id}\",\n",
        "  \"emotional\": 0 or 1,\n",
        "  \"physical\": 0 or 1,\n",
        "  \"sexual\": 0 or 1\n",
        "}}\n",
        "</json>\n",
        "\"\"\".strip()\n",
        "\n",
        "# Results directory (will be created if it doesn't exist)\n",
        "RESULTS_DIR = \"w4/qwen\"\n",
        "\n",
        "# Dataset path\n",
        "DATASET_PATH = \"../Dataset/reddit_data.csv\"\n",
        "\n",
        "# Model name\n",
        "MODEL_NAME = \"Qwen/Qwen2.5-7B-Instruct\"\n",
        "\n",
        "# Number of samples to process (set to None to process all)\n",
        "NUM_SAMPLES = None\n",
        "\n",
        "# Output filename (without extension)\n",
        "OUTPUT_FILENAME = \"multilabel_predictions\"\n",
        "\n",
        "# =========================================================\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%pip install -q transformers torch accelerate\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(DATASET_PATH)\n",
        "print(f\"Dataset loaded: {len(df)} rows\")\n",
        "\n",
        "# Limit to NUM_SAMPLES if specified\n",
        "if NUM_SAMPLES is not None:\n",
        "    df = df.head(NUM_SAMPLES)\n",
        "    print(f\"Processing {len(df)} samples\")\n",
        "\n",
        "# Display first few rows\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Qwen Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "print(f\"Loading {MODEL_NAME}...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        ")\n",
        "model.eval()\n",
        "print(\"Model loaded and ready!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate Predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "from typing import Dict, Any, Optional\n",
        "\n",
        "def extract_json_from_response(response: str) -> Optional[Dict[str, Any]]:\n",
        "    \"\"\"Extract JSON from model response, handling various formats.\"\"\"\n",
        "    # Try to find JSON between <json> tags\n",
        "    match = re.search(r\"<json[^>]*>\\s*(.*?)\\s*</json>\", response, re.DOTALL | re.IGNORECASE)\n",
        "    if match:\n",
        "        json_str = match.group(1).strip()\n",
        "        try:\n",
        "            return json.loads(json_str)\n",
        "        except json.JSONDecodeError:\n",
        "            pass\n",
        "    \n",
        "    # Try to find any JSON object in the response\n",
        "    match = re.search(r\"\\{[^{}]*\\\"(id|emotional|physical|sexual)\\\"[^{}]*\\}\", response, re.DOTALL)\n",
        "    if match:\n",
        "        try:\n",
        "            return json.loads(match.group(0))\n",
        "        except json.JSONDecodeError:\n",
        "            pass\n",
        "    \n",
        "    return None\n",
        "\n",
        "def make_prediction(text: str, sample_id: int) -> Dict[str, Any]:\n",
        "    \"\"\"Make a prediction for a single text sample.\"\"\"\n",
        "    # Format the prompt\n",
        "    prompt = PROMPT_TEMPLATE.format(text=text, sample_id=sample_id)\n",
        "    \n",
        "    try:\n",
        "        # Tokenize and generate\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=128,\n",
        "                temperature=0.0,\n",
        "                do_sample=False,\n",
        "            )\n",
        "        \n",
        "        # Decode the response\n",
        "        generated_tokens = outputs[0][inputs[\"input_ids\"].shape[-1]:]\n",
        "        response = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
        "        \n",
        "        # Extract JSON from response\n",
        "        prediction = extract_json_from_response(response)\n",
        "        \n",
        "        if prediction is None:\n",
        "            # Fallback: try to extract values from text\n",
        "            prediction = {\n",
        "                \"id\": sample_id,\n",
        "                \"emotional\": 1 if \"emotional\" in response.lower() and (\"1\" in response or \"true\" in response.lower()) else 0,\n",
        "                \"physical\": 1 if \"physical\" in response.lower() and (\"1\" in response or \"true\" in response.lower()) else 0,\n",
        "                \"sexual\": 1 if \"sexual\" in response.lower() and (\"1\" in response or \"true\" in response.lower()) else 0,\n",
        "            }\n",
        "        \n",
        "        # Ensure ID is set\n",
        "        prediction[\"id\"] = sample_id\n",
        "        \n",
        "        # Ensure binary values are integers (0 or 1)\n",
        "        for key in [\"emotional\", \"physical\", \"sexual\"]:\n",
        "            if key in prediction:\n",
        "                val = prediction[key]\n",
        "                if isinstance(val, bool):\n",
        "                    prediction[key] = 1 if val else 0\n",
        "                elif isinstance(val, (int, float)):\n",
        "                    prediction[key] = 1 if val > 0 else 0\n",
        "                else:\n",
        "                    prediction[key] = 0\n",
        "        \n",
        "        return {\n",
        "            \"id\": sample_id,\n",
        "            \"text\": text,\n",
        "            \"emotional\": prediction.get(\"emotional\", 0),\n",
        "            \"physical\": prediction.get(\"physical\", 0),\n",
        "            \"sexual\": prediction.get(\"sexual\", 0),\n",
        "            \"raw_response\": response,\n",
        "        }\n",
        "    \n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"id\": sample_id,\n",
        "            \"text\": text,\n",
        "            \"emotional\": 0,\n",
        "            \"physical\": 0,\n",
        "            \"sexual\": 0,\n",
        "            \"raw_response\": f\"ERROR: {str(e)}\",\n",
        "        }\n",
        "\n",
        "print(\"Starting prediction generation...\")\n",
        "predictions = []\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    text = row[\"items\"] if \"items\" in df.columns else str(row.iloc[0])\n",
        "    sample_id = int(idx)\n",
        "    \n",
        "    print(f\"Processing sample {sample_id}...\", end=\" \")\n",
        "    pred = make_prediction(text, sample_id)\n",
        "    predictions.append(pred)\n",
        "    print(f\"Done (emotional={pred['emotional']}, physical={pred['physical']}, sexual={pred['sexual']})\")\n",
        "\n",
        "print(f\"\\nGenerated {len(predictions)} predictions!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "# Create results directory if it doesn't exist\n",
        "results_path = Path(RESULTS_DIR)\n",
        "results_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Generate output filename with timestamp\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "output_file = results_path / f\"{OUTPUT_FILENAME}_{timestamp}.json\"\n",
        "\n",
        "# Save predictions to JSON\n",
        "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(predictions, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(f\"Results saved to: {output_file}\")\n",
        "print(f\"Total predictions: {len(predictions)}\")\n",
        "\n",
        "# Display summary statistics\n",
        "emotional_count = sum(1 for p in predictions if p[\"emotional\"] == 1)\n",
        "physical_count = sum(1 for p in predictions if p[\"physical\"] == 1)\n",
        "sexual_count = sum(1 for p in predictions if p[\"sexual\"] == 1)\n",
        "\n",
        "print(f\"\\nSummary:\")\n",
        "print(f\"  Emotional abuse: {emotional_count} ({100*emotional_count/len(predictions):.1f}%)\")\n",
        "print(f\"  Physical abuse: {physical_count} ({100*physical_count/len(predictions):.1f}%)\")\n",
        "print(f\"  Sexual abuse: {sexual_count} ({100*sexual_count/len(predictions):.1f}%)\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
