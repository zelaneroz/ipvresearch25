{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a9060ed",
   "metadata": {},
   "source": [
    "# Error Analysis: Binary & Multilabel Predictions\n",
    "\n",
    "This notebook analyzes model errors for both binary and multilabel IPV classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0742c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional\n",
    "\n",
    "# ========== CONFIGURATION ==========\n",
    "# Choose analysis mode: \"binary\" or \"multilabel\"\n",
    "ANALYSIS_MODE = \"binary\"  # Change to \"multilabel\" for multilabel analysis\n",
    "\n",
    "# Ground truth CSV path\n",
    "TRUTH_CSV_PATH = \"../../Dataset/reddit_data.csv\"\n",
    "\n",
    "# Predictions JSON path (adjust based on mode)\n",
    "if ANALYSIS_MODE == \"binary\":\n",
    "    PREDICTIONS_JSON_PATH = \"../w3/qwen/binary_fewshot.json\"\n",
    "elif ANALYSIS_MODE == \"multilabel\":\n",
    "    PREDICTIONS_JSON_PATH = \"../w4/qwen/multilabel_predictions.json\"  # Update with your path\n",
    "\n",
    "# ====================================\n",
    "\n",
    "print(f\"Analysis mode: {ANALYSIS_MODE}\")\n",
    "print(f\"Truth CSV: {TRUTH_CSV_PATH}\")\n",
    "print(f\"Predictions JSON: {PREDICTIONS_JSON_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f80fec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_type</th>\n",
       "      <th>extracted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>fewshot</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>fewshot</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>fewshot</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>fewshot</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>fewshot</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>613</td>\n",
       "      <td>fewshot</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>614</td>\n",
       "      <td>fewshot</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>615</td>\n",
       "      <td>fewshot</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>616</td>\n",
       "      <td>fewshot</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>617</td>\n",
       "      <td>fewshot</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>618 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id prompt_type extracted_label\n",
       "0      0     fewshot         NOT_IPV\n",
       "1      1     fewshot         NOT_IPV\n",
       "2      2     fewshot         NOT_IPV\n",
       "3      3     fewshot         NOT_IPV\n",
       "4      4     fewshot         NOT_IPV\n",
       "..   ...         ...             ...\n",
       "613  613     fewshot         NOT_IPV\n",
       "614  614     fewshot         NOT_IPV\n",
       "615  615     fewshot         NOT_IPV\n",
       "616  616     fewshot         NOT_IPV\n",
       "617  617     fewshot         NOT_IPV\n",
       "\n",
       "[618 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 1. Load Ground Truth & Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57403d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>items</th>\n",
       "      <th>Physical Abuse</th>\n",
       "      <th>Emotional Abuse</th>\n",
       "      <th>Sexual Abuse</th>\n",
       "      <th>Tag</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I'm sitting here with a goofy smile and feelin...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's really boosting my confidence when he say...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>I never imagined that someone could make me s...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>He motivates me to become the best version of ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>He’s like a best friend that I can also live w...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>613</td>\n",
       "      <td>He has never said anything negative about the ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>614</td>\n",
       "      <td>You'd think that in theory online dating would...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>615</td>\n",
       "      <td>I searched for a similar type post because I a...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>616</td>\n",
       "      <td>So let me explain first, my fiance and me have...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>617</td>\n",
       "      <td>For the record, my girlfriend has politely tur...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>618 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                              items  \\\n",
       "0             0  I'm sitting here with a goofy smile and feelin...   \n",
       "1             1  It's really boosting my confidence when he say...   \n",
       "2             2   I never imagined that someone could make me s...   \n",
       "3             3  He motivates me to become the best version of ...   \n",
       "4             4  He’s like a best friend that I can also live w...   \n",
       "..          ...                                                ...   \n",
       "613         613  He has never said anything negative about the ...   \n",
       "614         614  You'd think that in theory online dating would...   \n",
       "615         615  I searched for a similar type post because I a...   \n",
       "616         616  So let me explain first, my fiance and me have...   \n",
       "617         617  For the record, my girlfriend has politely tur...   \n",
       "\n",
       "     Physical Abuse  Emotional Abuse  Sexual Abuse    Tag  type  \n",
       "0             False            False         False  False  soft  \n",
       "1             False            False         False  False  soft  \n",
       "2             False            False         False  False  soft  \n",
       "3             False            False         False  False  soft  \n",
       "4             False            False         False  False  soft  \n",
       "..              ...              ...           ...    ...   ...  \n",
       "613           False            False         False  False  soft  \n",
       "614           False            False         False  False  soft  \n",
       "615           False            False         False  False  soft  \n",
       "616           False            False         False  False  soft  \n",
       "617           False            False         False  False  soft  \n",
       "\n",
       "[618 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load ground truth CSV\n",
    "truth = pd.read_csv(TRUTH_CSV_PATH)\n",
    "\n",
    "# Standardize column names\n",
    "truth = truth.rename(columns={\n",
    "    \"Emotional Abuse\": \"emotional\",\n",
    "    \"Physical Abuse\": \"physical\",\n",
    "    \"Sexual Abuse\": \"sexual\",\n",
    "    \"items\": \"text\"\n",
    "})\n",
    "\n",
    "# Ensure ID column exists\n",
    "if \"id\" not in truth.columns:\n",
    "    truth[\"id\"] = truth.index\n",
    "\n",
    "# For binary analysis: create Tag column from abuse types\n",
    "if ANALYSIS_MODE == \"binary\":\n",
    "    truth[\"Tag\"] = (truth[\"emotional\"] | truth[\"physical\"] | truth[\"sexual\"]).astype(bool)\n",
    "\n",
    "print(f\"Ground truth loaded: {len(truth)} samples\")\n",
    "print(f\"Columns: {truth.columns.tolist()}\")\n",
    "truth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190bf25e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>items</th>\n",
       "      <th>Physical Abuse</th>\n",
       "      <th>Emotional Abuse</th>\n",
       "      <th>Sexual Abuse</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sometimes when my partner speaks to me, I feel...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>I know that if she senses frustration directed...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>As she was yelling, I continued to ask why she...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>She got angry and we blew up again.</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>He says a lot of this was insecurity, validati...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>Don't come at me saying you're the \"relationsh...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>Because calling them sexless virgins is an eas...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>You can't be out here getting offended when I ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>I am in bed now, tearing up after being hung u...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>But my mind keeps on wondering and lingering o...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>IPV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 items  Physical Abuse  \\\n",
       "16   Sometimes when my partner speaks to me, I feel...           False   \n",
       "18   I know that if she senses frustration directed...           False   \n",
       "20   As she was yelling, I continued to ask why she...           False   \n",
       "22                 She got angry and we blew up again.           False   \n",
       "28   He says a lot of this was insecurity, validati...           False   \n",
       "..                                                 ...             ...   \n",
       "390  Don't come at me saying you're the \"relationsh...           False   \n",
       "424  Because calling them sexless virgins is an eas...           False   \n",
       "452  You can't be out here getting offended when I ...           False   \n",
       "540  I am in bed now, tearing up after being hung u...           False   \n",
       "555  But my mind keeps on wondering and lingering o...           False   \n",
       "\n",
       "     Emotional Abuse  Sexual Abuse Prediction  \n",
       "16              True         False    NOT_IPV  \n",
       "18              True         False    NOT_IPV  \n",
       "20              True         False    NOT_IPV  \n",
       "22              True         False    NOT_IPV  \n",
       "28              True         False    NOT_IPV  \n",
       "..               ...           ...        ...  \n",
       "390            False         False        IPV  \n",
       "424            False         False        IPV  \n",
       "452            False         False        IPV  \n",
       "540            False         False        IPV  \n",
       "555            False         False        IPV  \n",
       "\n",
       "[66 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load predictions JSON\n",
    "with open(PREDICTIONS_JSON_PATH) as f:\n",
    "    preds_data = json.load(f)\n",
    "\n",
    "preds = pd.DataFrame(preds_data)\n",
    "\n",
    "# Handle binary vs multilabel differently\n",
    "if ANALYSIS_MODE == \"binary\":\n",
    "    # Binary predictions: extract label\n",
    "    if \"extracted_label\" in preds.columns:\n",
    "        preds[\"predicted_ipv\"] = (preds[\"extracted_label\"] == \"IPV\").astype(bool)\n",
    "    elif \"label\" in preds.columns:\n",
    "        preds[\"predicted_ipv\"] = (preds[\"label\"] == \"IPV\").astype(bool)\n",
    "    else:\n",
    "        raise ValueError(\"Binary predictions must have 'extracted_label' or 'label' column\")\n",
    "    \n",
    "    # Ensure ID column\n",
    "    if \"id\" not in preds.columns:\n",
    "        preds[\"id\"] = preds.index\n",
    "    \n",
    "    # Merge on ID\n",
    "    df = truth.merge(preds[[\"id\", \"predicted_ipv\"]], on=\"id\", how=\"inner\")\n",
    "    \n",
    "    # Compute wrong predictions (binary)\n",
    "    df[\"wrong\"] = df[\"Tag\"] != df[\"predicted_ipv\"]\n",
    "    df[\"predicted_label\"] = df[\"predicted_ipv\"].map({True: \"IPV\", False: \"NOT_IPV\"})\n",
    "    \n",
    "elif ANALYSIS_MODE == \"multilabel\":\n",
    "    # Multilabel predictions: extract emotional, physical, sexual\n",
    "    if \"id\" not in preds.columns:\n",
    "        preds[\"id\"] = preds.index\n",
    "    \n",
    "    # Ensure binary values (0/1) in predictions\n",
    "    for col in [\"emotional\", \"physical\", \"sexual\"]:\n",
    "        if col in preds.columns:\n",
    "            preds[f\"{col}_pred\"] = preds[col].astype(int).clip(0, 1)\n",
    "        else:\n",
    "            preds[f\"{col}_pred\"] = 0\n",
    "    \n",
    "    # Prepare truth columns (convert boolean to int)\n",
    "    truth_for_merge = truth[[\"id\", \"text\", \"emotional\", \"physical\", \"sexual\"]].copy()\n",
    "    truth_for_merge[\"emotional_true\"] = truth_for_merge[\"emotional\"].astype(int)\n",
    "    truth_for_merge[\"physical_true\"] = truth_for_merge[\"physical\"].astype(int)\n",
    "    truth_for_merge[\"sexual_true\"] = truth_for_merge[\"sexual\"].astype(int)\n",
    "    \n",
    "    # Merge on ID\n",
    "    df = truth_for_merge.merge(\n",
    "        preds[[\"id\", \"emotional_pred\", \"physical_pred\", \"sexual_pred\"]],\n",
    "        on=\"id\",\n",
    "        how=\"inner\"\n",
    "    )\n",
    "    \n",
    "    # Compute wrong predictions (any mismatch)\n",
    "    df[\"wrong\"] = (\n",
    "        (df[\"emotional_true\"] != df[\"emotional_pred\"]) |\n",
    "        (df[\"physical_true\"] != df[\"physical_pred\"]) |\n",
    "        (df[\"sexual_true\"] != df[\"sexual_pred\"])\n",
    "    )\n",
    "    \n",
    "    # Create error pattern column\n",
    "    df[\"error_pattern\"] = (\n",
    "        (df[\"physical_true\"] != df[\"physical_pred\"]).map({True: \"P\", False: \"\"}) +\n",
    "        (df[\"emotional_true\"] != df[\"emotional_pred\"]).map({True: \"E\", False: \"\"}) +\n",
    "        (df[\"sexual_true\"] != df[\"sexual_pred\"]).map({True: \"S\", False: \"\"})\n",
    "    ).replace({\"\": \"None\"})\n",
    "\n",
    "print(f\"Predictions loaded: {len(preds)} samples\")\n",
    "print(f\"Merged dataset: {len(df)} samples\")\n",
    "print(f\"Wrong predictions: {df['wrong'].sum()} ({100*df['wrong'].sum()/len(df):.1f}%)\")\n",
    "preds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854ee4cc",
   "metadata": {},
   "source": [
    "## 2. Extract Wrong Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464db9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>items</th>\n",
       "      <th>Physical Abuse</th>\n",
       "      <th>Emotional Abuse</th>\n",
       "      <th>Sexual Abuse</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sometimes when my partner speaks to me, I feel...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>I know that if she senses frustration directed...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>As she was yelling, I continued to ask why she...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>She got angry and we blew up again.</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>He says a lot of this was insecurity, validati...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>The lies are what killed me.</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>She has a very short fuse and once she gets an...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Shes still angry at me about it now hours on.</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>We’ve also fought about a lot of other stuff,...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>He ended up breaking his phone out of anger.</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>He mildly objected to me visiting family out o...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>He would hesitate to give approval for time sp...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>He downplayed his conduct, and denied that he ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>He was hiding that from me.</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>We moved in together shortly after and I found...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>I would tell you that his temper is very bad a...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Over the last few years, she's just gotten t...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>It pretty  much escalated from there.</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>He tricked me into  coming back up.</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>I also saw that a few days before that she had...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Two months into dating I found out he was on e...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>She becomes inconsolable,  angry, mad all the ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Those two nights that he left to go to the bar...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>He developed an emotional connection with her ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>He spoke to her lovingly and I was quite jealous.</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>I was also so scared  about the bruising that ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>She even tried to hide it from  me!</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>This to me is textbook emotional cheating.</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>As the relationship went on, they got worse an...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>She accuses me of being lazy.</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>She says that I never deliver (because I have ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>She says I am a slob.</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>She said at one point she didn’t think I would...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>I have thrown objects in frustration before, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Now I understand that you can''t control what ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>One night, I ventured downstairs and he was in...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>I then hung up and went straight to his texts ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>I just said one thing and it turned into this ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>I didn't believe she was capable of something ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>It hurt so badly.</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>I was confused through most of this though, be...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>The lies and manipulation.</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>She gets  upset/offended pretty easily by my b...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>He also has an  imgur account filled with phot...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>Just to briefly mention, he also  was shady in...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>My preferences have, historically, not mattere...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>I felt deeply betrayed.</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>She staged having an overdose only to laugh  i...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>He didn’t stop yelling.</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>I’d added too much water, and so he’d berated ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>And  where he’d just bought a shotgun, that ki...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>At this point, I’ve completely given up on get...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>He says that all I care about is sex, which  i...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>My wife would always use the daughter in argum...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>I never felt so isolated before.</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>I told her to stop shouting and that it was ok...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>She was stone cold \"that your problem\".</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>It used to be much more frequent he would be a...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>I feel like I can't trust him now, that he'd a...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NOT_IPV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 items  Physical Abuse  \\\n",
       "16   Sometimes when my partner speaks to me, I feel...           False   \n",
       "18   I know that if she senses frustration directed...           False   \n",
       "20   As she was yelling, I continued to ask why she...           False   \n",
       "22                 She got angry and we blew up again.           False   \n",
       "28   He says a lot of this was insecurity, validati...           False   \n",
       "29                        The lies are what killed me.           False   \n",
       "37   She has a very short fuse and once she gets an...           False   \n",
       "39       Shes still angry at me about it now hours on.           False   \n",
       "45    We’ve also fought about a lot of other stuff,...           False   \n",
       "50        He ended up breaking his phone out of anger.           False   \n",
       "56   He mildly objected to me visiting family out o...           False   \n",
       "57   He would hesitate to give approval for time sp...           False   \n",
       "59   He downplayed his conduct, and denied that he ...           False   \n",
       "70                         He was hiding that from me.           False   \n",
       "73   We moved in together shortly after and I found...           False   \n",
       "87   I would tell you that his temper is very bad a...            True   \n",
       "99     Over the last few years, she's just gotten t...           False   \n",
       "103              It pretty  much escalated from there.           False   \n",
       "112                He tricked me into  coming back up.           False   \n",
       "125  I also saw that a few days before that she had...           False   \n",
       "135  Two months into dating I found out he was on e...           False   \n",
       "148  She becomes inconsolable,  angry, mad all the ...           False   \n",
       "151  Those two nights that he left to go to the bar...           False   \n",
       "152  He developed an emotional connection with her ...           False   \n",
       "153  He spoke to her lovingly and I was quite jealous.           False   \n",
       "168  I was also so scared  about the bruising that ...            True   \n",
       "175                She even tried to hide it from  me!           False   \n",
       "176         This to me is textbook emotional cheating.           False   \n",
       "182  As the relationship went on, they got worse an...           False   \n",
       "184                      She accuses me of being lazy.           False   \n",
       "185  She says that I never deliver (because I have ...           False   \n",
       "186                              She says I am a slob.           False   \n",
       "187  She said at one point she didn’t think I would...           False   \n",
       "191   I have thrown objects in frustration before, ...           False   \n",
       "204  Now I understand that you can''t control what ...           False   \n",
       "205  One night, I ventured downstairs and he was in...           False   \n",
       "206  I then hung up and went straight to his texts ...           False   \n",
       "209  I just said one thing and it turned into this ...           False   \n",
       "218  I didn't believe she was capable of something ...           False   \n",
       "219                                  It hurt so badly.           False   \n",
       "231  I was confused through most of this though, be...           False   \n",
       "233                         The lies and manipulation.           False   \n",
       "235  She gets  upset/offended pretty easily by my b...           False   \n",
       "250  He also has an  imgur account filled with phot...           False   \n",
       "252  Just to briefly mention, he also  was shady in...           False   \n",
       "258  My preferences have, historically, not mattere...           False   \n",
       "260                            I felt deeply betrayed.           False   \n",
       "262  She staged having an overdose only to laugh  i...           False   \n",
       "278                            He didn’t stop yelling.           False   \n",
       "284  I’d added too much water, and so he’d berated ...           False   \n",
       "289  And  where he’d just bought a shotgun, that ki...            True   \n",
       "293  At this point, I’ve completely given up on get...           False   \n",
       "308  He says that all I care about is sex, which  i...           False   \n",
       "315  My wife would always use the daughter in argum...           False   \n",
       "320                   I never felt so isolated before.           False   \n",
       "324  I told her to stop shouting and that it was ok...           False   \n",
       "327            She was stone cold \"that your problem\".           False   \n",
       "330  It used to be much more frequent he would be a...           False   \n",
       "334  I feel like I can't trust him now, that he'd a...           False   \n",
       "\n",
       "     Emotional Abuse  Sexual Abuse Prediction  \n",
       "16              True         False    NOT_IPV  \n",
       "18              True         False    NOT_IPV  \n",
       "20              True         False    NOT_IPV  \n",
       "22              True         False    NOT_IPV  \n",
       "28              True         False    NOT_IPV  \n",
       "29              True         False    NOT_IPV  \n",
       "37              True         False    NOT_IPV  \n",
       "39              True         False    NOT_IPV  \n",
       "45              True         False    NOT_IPV  \n",
       "50              True         False    NOT_IPV  \n",
       "56              True         False    NOT_IPV  \n",
       "57              True         False    NOT_IPV  \n",
       "59              True         False    NOT_IPV  \n",
       "70              True         False    NOT_IPV  \n",
       "73              True         False    NOT_IPV  \n",
       "87              True         False    NOT_IPV  \n",
       "99              True         False    NOT_IPV  \n",
       "103             True         False    NOT_IPV  \n",
       "112             True         False    NOT_IPV  \n",
       "125             True         False    NOT_IPV  \n",
       "135             True         False    NOT_IPV  \n",
       "148             True         False    NOT_IPV  \n",
       "151             True         False    NOT_IPV  \n",
       "152             True         False    NOT_IPV  \n",
       "153             True         False    NOT_IPV  \n",
       "168            False         False    NOT_IPV  \n",
       "175             True         False    NOT_IPV  \n",
       "176             True         False    NOT_IPV  \n",
       "182             True         False    NOT_IPV  \n",
       "184             True         False    NOT_IPV  \n",
       "185             True         False    NOT_IPV  \n",
       "186             True         False    NOT_IPV  \n",
       "187             True         False    NOT_IPV  \n",
       "191             True         False    NOT_IPV  \n",
       "204            False          True    NOT_IPV  \n",
       "205             True         False    NOT_IPV  \n",
       "206             True         False    NOT_IPV  \n",
       "209             True         False    NOT_IPV  \n",
       "218             True         False    NOT_IPV  \n",
       "219             True         False    NOT_IPV  \n",
       "231             True         False    NOT_IPV  \n",
       "233             True         False    NOT_IPV  \n",
       "235             True         False    NOT_IPV  \n",
       "250             True         False    NOT_IPV  \n",
       "252             True          True    NOT_IPV  \n",
       "258             True         False    NOT_IPV  \n",
       "260             True         False    NOT_IPV  \n",
       "262             True         False    NOT_IPV  \n",
       "278             True         False    NOT_IPV  \n",
       "284             True         False    NOT_IPV  \n",
       "289             True         False    NOT_IPV  \n",
       "293             True         False    NOT_IPV  \n",
       "308             True          True    NOT_IPV  \n",
       "315             True         False    NOT_IPV  \n",
       "320             True         False    NOT_IPV  \n",
       "324             True         False    NOT_IPV  \n",
       "327             True         False    NOT_IPV  \n",
       "330             True         False    NOT_IPV  \n",
       "334             True         False    NOT_IPV  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract wrong predictions\n",
    "wrongs = df[df[\"wrong\"]].copy()\n",
    "\n",
    "print(f\"Total wrong predictions: {len(wrongs)}\")\n",
    "print(f\"Wrong percentage: {100*len(wrongs)/len(df):.2f}%\")\n",
    "\n",
    "if ANALYSIS_MODE == \"binary\":\n",
    "    false_negatives = wrongs[wrongs[\"predicted_label\"] == \"NOT_IPV\"]\n",
    "    false_positives = wrongs[wrongs[\"predicted_label\"] == \"IPV\"]\n",
    "    \n",
    "    print(f\"\\nBinary Classification Errors:\")\n",
    "    print(f\"  False Negatives (IPV → NOT_IPV): {len(false_negatives)}\")\n",
    "    print(f\"  False Positives (NOT_IPV → IPV): {len(false_positives)}\")\n",
    "    \n",
    "elif ANALYSIS_MODE == \"multilabel\":\n",
    "    print(f\"\\nMultilabel Error Patterns:\")\n",
    "    print(wrongs[\"error_pattern\"].value_counts())\n",
    "\n",
    "wrongs.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44e1542",
   "metadata": {},
   "source": [
    "## 3. Binary Analysis: False Negatives & False Positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fc98f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "If your answer to a direct consequence of your own willing actions is \"dismemberment\" or \"poisoning\" of anyone who is inconveniencing you (aka fetus) then you can't be trusted with the reins of your own life, let alone with the (indirect) reins of 4 years of an entire nation's future.What will change my view?Let's start with what will not change it, since I fear most of you will try at least one of these:1.\n",
      "Some of his rules are;- don’t get married or have kids until you are 30- always wear a condom and make sure you supply the condom- put hot sauce in your condoms after use so if the bitch tries to put your semen in her after sex, she gets quite the burn - never spend more than $40 on a date- never take a woman to get food after the bar because you don’t want her to sober up nor will most women put out with jumbo jack breath- never answer your phones on weekends.\n",
      "Don't come at me saying you're the \"relationship  kind of guy\".\n",
      "Because calling them sexless virgins is an easy way to show them their low value and status in society.\n",
      "You can't be out here getting offended when I ask you to please move to the side mam.\n",
      "I am in bed now, tearing up after being hung up on since I am annoying, as one of them said it.\n",
      "But my mind keeps on wondering and lingering on the fact that they have had over a dozen sexual relationships while this is my very first.\n"
     ]
    }
   ],
   "source": [
    "if ANALYSIS_MODE == \"binary\":\n",
    "    # False Negatives: IPV cases predicted as NOT_IPV\n",
    "    fn = wrongs[wrongs[\"predicted_label\"] == \"NOT_IPV\"].copy()\n",
    "    print(f\"False Negatives ({len(fn)} cases):\")\n",
    "    print(\"=\" * 80)\n",
    "    fn_display = fn[[\"text\", \"emotional\", \"physical\", \"sexual\", \"predicted_label\"]].copy()\n",
    "    fn_display.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29851908",
   "metadata": {},
   "source": [
    "## 4. Binary Analysis: False Positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39beb145",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYSIS_MODE == \"binary\":\n",
    "    # False Positives: NOT_IPV cases predicted as IPV\n",
    "    fp = wrongs[wrongs[\"predicted_label\"] == \"IPV\"].copy()\n",
    "    print(f\"False Positives ({len(fp)} cases):\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for idx, row in fp.iterrows():\n",
    "        print(f\"\\nSample {row['id']}:\")\n",
    "        print(f\"Text: {row['text'][:200]}...\")\n",
    "        print(f\"Predicted: {row['predicted_label']}\")\n",
    "        print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9a1422",
   "metadata": {},
   "source": [
    "## 5. Multilabel Analysis: Error Patterns by Abuse Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873eadeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYSIS_MODE == \"multilabel\":\n",
    "    # Count errors by abuse type\n",
    "    error_counts = {\n",
    "        \"physical_only\": wrongs[\n",
    "            (wrongs[\"physical_true\"] != wrongs[\"physical_pred\"]) &\n",
    "            (wrongs[\"emotional_true\"] == wrongs[\"emotional_pred\"]) &\n",
    "            (wrongs[\"sexual_true\"] == wrongs[\"sexual_pred\"])\n",
    "        ],\n",
    "        \"emotional_only\": wrongs[\n",
    "            (wrongs[\"emotional_true\"] != wrongs[\"emotional_pred\"]) &\n",
    "            (wrongs[\"physical_true\"] == wrongs[\"physical_pred\"]) &\n",
    "            (wrongs[\"sexual_true\"] == wrongs[\"sexual_pred\"])\n",
    "        ],\n",
    "        \"sexual_only\": wrongs[\n",
    "            (wrongs[\"sexual_true\"] != wrongs[\"sexual_pred\"]) &\n",
    "            (wrongs[\"physical_true\"] == wrongs[\"physical_pred\"]) &\n",
    "            (wrongs[\"emotional_true\"] == wrongs[\"emotional_pred\"])\n",
    "        ],\n",
    "        \"multiple_errors\": wrongs[\n",
    "            ((wrongs[\"physical_true\"] != wrongs[\"physical_pred\"]).astype(int) +\n",
    "             (wrongs[\"emotional_true\"] != wrongs[\"emotional_pred\"]).astype(int) +\n",
    "             (wrongs[\"sexual_true\"] != wrongs[\"sexual_pred\"]).astype(int)) > 1\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    print(\"Error breakdown by abuse type:\")\n",
    "    print(\"=\" * 80)\n",
    "    for error_type, df_err in error_counts.items():\n",
    "        print(f\"\\n{error_type}: {len(df_err)} cases\")\n",
    "        if len(df_err) > 0:\n",
    "            display_cols = [\"text\", \"emotional_true\", \"emotional_pred\", \n",
    "                          \"physical_true\", \"physical_pred\", \n",
    "                          \"sexual_true\", \"sexual_pred\"]\n",
    "            print(df_err[display_cols].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30c5a77",
   "metadata": {},
   "source": [
    "## 6. Error Pattern Distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bec4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYSIS_MODE == \"multilabel\":\n",
    "    # Count error patterns\n",
    "    error_pattern_counts = wrongs[\"error_pattern\"].value_counts()\n",
    "    \n",
    "    print(\"Error Pattern Distribution:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(error_pattern_counts)\n",
    "    print(\"\\nLegend:\")\n",
    "    print(\"  P = Physical abuse error\")\n",
    "    print(\"  E = Emotional abuse error\")\n",
    "    print(\"  S = Sexual abuse error\")\n",
    "    print(\"  PE = Physical + Emotional errors\")\n",
    "    print(\"  etc.\")\n",
    "    \n",
    "    # Visualize error patterns\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Pie chart\n",
    "    error_pattern_counts.plot(kind=\"pie\", ax=axes[0], autopct=\"%1.1f%%\", startangle=90)\n",
    "    axes[0].set_title(\"Error Pattern Distribution\")\n",
    "    axes[0].set_ylabel(\"\")\n",
    "    \n",
    "    # Bar chart\n",
    "    error_pattern_counts.plot(kind=\"bar\", ax=axes[1])\n",
    "    axes[1].set_title(\"Error Pattern Counts\")\n",
    "    axes[1].set_xlabel(\"Error Pattern\")\n",
    "    axes[1].set_ylabel(\"Count\")\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28771276",
   "metadata": {},
   "source": [
    "## 7. Visualize Errors by Abuse Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80639f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYSIS_MODE == \"multilabel\":\n",
    "    # Count wrong predictions per abuse type\n",
    "    wrong_by_type = pd.DataFrame({\n",
    "        \"Emotional\": (wrongs[\"emotional_true\"] != wrongs[\"emotional_pred\"]).sum(),\n",
    "        \"Physical\": (wrongs[\"physical_true\"] != wrongs[\"physical_pred\"]).sum(),\n",
    "        \"Sexual\": (wrongs[\"sexual_true\"] != wrongs[\"sexual_pred\"]).sum(),\n",
    "    }, index=[0])\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Bar chart of wrong counts per type\n",
    "    wrong_by_type.T.plot(kind=\"bar\", ax=axes[0], legend=False)\n",
    "    axes[0].set_title(\"Wrong Predictions per Abuse Type\")\n",
    "    axes[0].set_xlabel(\"Abuse Type\")\n",
    "    axes[0].set_ylabel(\"Number of Errors\")\n",
    "    axes[0].tick_params(axis='x', rotation=0)\n",
    "    \n",
    "    # Pie chart\n",
    "    wrong_by_type.T[0].plot(kind=\"pie\", ax=axes[1], autopct=\"%1.1f%%\", legend=False)\n",
    "    axes[1].set_title(\"Error Distribution by Abuse Type\")\n",
    "    axes[1].set_ylabel(\"\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Error counts by type:\")\n",
    "    print(wrong_by_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f21137",
   "metadata": {},
   "source": [
    "## 8. Linguistic Pattern Analysis: Soft vs Hard Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a39870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with wrongs to get type information\n",
    "if \"type\" in truth.columns:\n",
    "    wrongs_with_type = wrongs.merge(\n",
    "        truth[[\"id\", \"type\"]], \n",
    "        on=\"id\", \n",
    "        how=\"left\"\n",
    "    )\n",
    "    \n",
    "    print(\"Error distribution by statement type:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    if ANALYSIS_MODE == \"binary\":\n",
    "        type_errors = wrongs_with_type.groupby(\"type\").size()\n",
    "        print(type_errors)\n",
    "        \n",
    "        # Visualize\n",
    "        type_errors.plot(kind=\"bar\", figsize=(10, 5))\n",
    "        plt.title(\"Error Counts by Statement Type\")\n",
    "        plt.xlabel(\"Statement Type\")\n",
    "        plt.ylabel(\"Number of Errors\")\n",
    "        plt.tick_params(axis='x', rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    elif ANALYSIS_MODE == \"multilabel\":\n",
    "        # Cross-tabulation of type vs error pattern\n",
    "        type_error_cross = pd.crosstab(wrongs_with_type[\"type\"], wrongs_with_type[\"error_pattern\"])\n",
    "        print(\"\\nCross-tabulation: Statement Type vs Error Pattern\")\n",
    "        print(type_error_cross)\n",
    "        \n",
    "        # Visualize\n",
    "        type_error_cross.plot(kind=\"bar\", stacked=True, figsize=(12, 6))\n",
    "        plt.title(\"Error Patterns by Statement Type\")\n",
    "        plt.xlabel(\"Statement Type\")\n",
    "        plt.ylabel(\"Number of Errors\")\n",
    "        plt.legend(title=\"Error Pattern\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.tick_params(axis='x', rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"'type' column not found in ground truth. Skipping linguistic pattern analysis.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30986b5",
   "metadata": {},
   "source": [
    "## 9. Detailed Wrong Examples by Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f39512",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYSIS_MODE == \"multilabel\":\n",
    "    # Show examples for each error pattern\n",
    "    print(\"Examples of Wrong Predictions by Error Pattern:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for pattern in wrongs[\"error_pattern\"].unique():\n",
    "        if pattern == \"None\":\n",
    "            continue\n",
    "        \n",
    "        pattern_wrongs = wrongs[wrongs[\"error_pattern\"] == pattern]\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Error Pattern: {pattern} ({len(pattern_wrongs)} cases)\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        for idx, row in pattern_wrongs.head(5).iterrows():\n",
    "            print(f\"\\nSample ID: {row['id']}\")\n",
    "            print(f\"Text: {row['text'][:300]}...\")\n",
    "            print(f\"True:  E={row['emotional_true']}, P={row['physical_true']}, S={row['sexual_true']}\")\n",
    "            print(f\"Pred:  E={row['emotional_pred']}, P={row['physical_pred']}, S={row['sexual_pred']}\")\n",
    "            print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d36884",
   "metadata": {},
   "source": [
    "## 10. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddb02a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Summary Statistics\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Correct predictions: {len(df) - len(wrongs)} ({100*(len(df)-len(wrongs))/len(df):.2f}%)\")\n",
    "print(f\"Wrong predictions: {len(wrongs)} ({100*len(wrongs)/len(df):.2f}%)\")\n",
    "\n",
    "if ANALYSIS_MODE == \"binary\":\n",
    "    print(f\"\\nBinary Classification:\")\n",
    "    print(f\"  False Negatives: {(wrongs['predicted_label'] == 'NOT_IPV').sum()}\")\n",
    "    print(f\"  False Positives: {(wrongs['predicted_label'] == 'IPV').sum()}\")\n",
    "    \n",
    "elif ANALYSIS_MODE == \"multilabel\":\n",
    "    print(f\"\\nMultilabel Classification:\")\n",
    "    print(f\"  Physical abuse errors: {(wrongs['physical_true'] != wrongs['physical_pred']).sum()}\")\n",
    "    print(f\"  Emotional abuse errors: {(wrongs['emotional_true'] != wrongs['emotional_pred']).sum()}\")\n",
    "    print(f\"  Sexual abuse errors: {(wrongs['sexual_true'] != wrongs['sexual_pred']).sum()}\")\n",
    "    \n",
    "    print(f\"\\nMost common error pattern: {wrongs['error_pattern'].mode().iloc[0] if len(wrongs) > 0 else 'N/A'}\")\n",
    "    \n",
    "    # Per-label accuracy\n",
    "    print(f\"\\nPer-Label Accuracy:\")\n",
    "    for label in [\"emotional\", \"physical\", \"sexual\"]:\n",
    "        correct = (df[f\"{label}_true\"] == df[f\"{label}_pred\"]).sum()\n",
    "        accuracy = 100 * correct / len(df)\n",
    "        print(f\"  {label.capitalize()}: {accuracy:.2f}% ({correct}/{len(df)})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1f8678",
   "metadata": {},
   "source": [
    "## 11. Confusion Matrix Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d00640",
   "metadata": {},
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score, f1_score\n",
    "\n",
    "if ANALYSIS_MODE == \"binary\":\n",
    "    # Binary confusion matrix\n",
    "    y_true = df[\"Tag\"].astype(int)\n",
    "    y_pred = df[\"predicted_ipv\"].astype(int)\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "                xticklabels=['NOT_IPV', 'IPV'],\n",
    "                yticklabels=['NOT_IPV', 'IPV'])\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('True')\n",
    "    ax.set_title('Binary Classification Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(classification_report(y_true, y_pred, target_names=['NOT_IPV', 'IPV']))\n",
    "    \n",
    "elif ANALYSIS_MODE == \"multilabel\":\n",
    "    # Confusion matrices for each label\n",
    "    labels = [\"emotional\", \"physical\", \"sexual\"]\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    for idx, label in enumerate(labels):\n",
    "        y_true = df[f\"{label}_true\"]\n",
    "        y_pred = df[f\"{label}_pred\"]\n",
    "        \n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        \n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx],\n",
    "                    xticklabels=['0', '1'],\n",
    "                    yticklabels=['0', '1'])\n",
    "        axes[idx].set_xlabel('Predicted')\n",
    "        axes[idx].set_ylabel('True')\n",
    "        axes[idx].set_title(f'{label.capitalize()} Abuse Confusion Matrix')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Per-label metrics\n",
    "    print(\"\\nPer-Label Classification Metrics:\")\n",
    "    print(\"=\" * 80)\n",
    "    for label in labels:\n",
    "        y_true = df[f\"{label}_true\"]\n",
    "        y_pred = df[f\"{label}_pred\"]\n",
    "        \n",
    "        precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "        \n",
    "        print(f\"\\n{label.capitalize()}:\")\n",
    "        print(f\"  Precision: {precision:.3f}\")\n",
    "        print(f\"  Recall: {recall:.3f}\")\n",
    "        print(f\"  F1-Score: {f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11c2b29",
   "metadata": {},
   "source": [
    "## 12. Text Length Analysis: Does Text Length Correlate with Errors?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f2467e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add text length column\n",
    "df[\"text_length\"] = df[\"text\"].str.len()\n",
    "df[\"word_count\"] = df[\"text\"].str.split().str.len()\n",
    "\n",
    "# Compare text lengths for correct vs wrong predictions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Character length distribution\n",
    "df.boxplot(column=\"text_length\", by=\"wrong\", ax=axes[0])\n",
    "axes[0].set_title(\"Text Length (characters) by Prediction Accuracy\")\n",
    "axes[0].set_xlabel(\"Wrong Prediction\")\n",
    "axes[0].set_ylabel(\"Character Count\")\n",
    "axes[0].set_xticklabels(['Correct', 'Wrong'])\n",
    "\n",
    "# Word count distribution\n",
    "df.boxplot(column=\"word_count\", by=\"wrong\", ax=axes[1])\n",
    "axes[1].set_title(\"Word Count by Prediction Accuracy\")\n",
    "axes[1].set_xlabel(\"Wrong Prediction\")\n",
    "axes[1].set_ylabel(\"Word Count\")\n",
    "axes[1].set_xticklabels(['Correct', 'Wrong'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistical summary\n",
    "print(\"Text Length Statistics:\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nCorrect predictions:\")\n",
    "print(df[~df[\"wrong\"]][[\"text_length\", \"word_count\"]].describe())\n",
    "print(\"\\nWrong predictions:\")\n",
    "print(df[df[\"wrong\"]][[\"text_length\", \"word_count\"]].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d03612e",
   "metadata": {},
   "source": [
    "## 13. Save Wrong Predictions for Further Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bbc503",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Prepare wrong predictions for export\n",
    "output_dir = Path(\"error_analysis_output\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "if ANALYSIS_MODE == \"binary\":\n",
    "    wrongs_export = wrongs[[\n",
    "        \"id\", \"text\", \"emotional\", \"physical\", \"sexual\",\n",
    "        \"Tag\", \"predicted_ipv\", \"predicted_label\"\n",
    "    ]].copy()\n",
    "    wrongs_export.columns = [\n",
    "        \"id\", \"text\", \"emotional_true\", \"physical_true\", \"sexual_true\",\n",
    "        \"ipv_true\", \"ipv_predicted\", \"predicted_label\"\n",
    "    ]\n",
    "    \n",
    "elif ANALYSIS_MODE == \"multilabel\":\n",
    "    wrongs_export = wrongs[[\n",
    "        \"id\", \"text\", \"emotional_true\", \"physical_true\", \"sexual_true\",\n",
    "        \"emotional_pred\", \"physical_pred\", \"sexual_pred\", \"error_pattern\"\n",
    "    ]].copy()\n",
    "\n",
    "# Save to CSV\n",
    "output_file = output_dir / f\"wrong_predictions_{ANALYSIS_MODE}_{timestamp}.csv\"\n",
    "wrongs_export.to_csv(output_file, index=False)\n",
    "print(f\"Wrong predictions saved to: {output_file}\")\n",
    "print(f\"Total wrong predictions exported: {len(wrongs_export)}\")\n",
    "\n",
    "# Also save full analysis data\n",
    "full_output_file = output_dir / f\"full_analysis_{ANALYSIS_MODE}_{timestamp}.csv\"\n",
    "df_export = df.copy()\n",
    "if \"text\" in df_export.columns:\n",
    "    # Truncate long texts for CSV readability\n",
    "    df_export[\"text\"] = df_export[\"text\"].str[:500] + \"...\"\n",
    "df_export.to_csv(full_output_file, index=False)\n",
    "print(f\"Full analysis data saved to: {full_output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8479c8ff",
   "metadata": {},
   "source": [
    "## 14. Keyword Analysis: Common Words in Wrong Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c11c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Simple word frequency analysis\n",
    "def get_words(text, min_length=3):\n",
    "    \"\"\"Extract words from text, filtering common stop words.\"\"\"\n",
    "    # Basic stop words\n",
    "    stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', \n",
    "                  'of', 'with', 'by', 'from', 'as', 'is', 'was', 'are', 'were', 'been',\n",
    "                  'be', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would',\n",
    "                  'could', 'should', 'may', 'might', 'must', 'can', 'this', 'that',\n",
    "                  'these', 'those', 'i', 'you', 'he', 'she', 'it', 'we', 'they',\n",
    "                  'me', 'him', 'her', 'us', 'them', 'my', 'your', 'his', 'her', 'its',\n",
    "                  'our', 'their', 'what', 'which', 'who', 'whom', 'whose', 'where',\n",
    "                  'when', 'why', 'how', 'all', 'each', 'every', 'both', 'few', 'more',\n",
    "                  'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own',\n",
    "                  'same', 'so', 'than', 'too', 'very', 'just'}\n",
    "    \n",
    "    words = re.findall(r'\\b[a-z]+\\b', text.lower())\n",
    "    return [w for w in words if len(w) >= min_length and w not in stop_words]\n",
    "\n",
    "# Analyze words in wrong vs correct predictions\n",
    "wrong_words = []\n",
    "correct_words = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    words = get_words(str(row[\"text\"]))\n",
    "    if row[\"wrong\"]:\n",
    "        wrong_words.extend(words)\n",
    "    else:\n",
    "        correct_words.extend(words)\n",
    "\n",
    "# Count frequencies\n",
    "wrong_word_counts = Counter(wrong_words)\n",
    "correct_word_counts = Counter(correct_words)\n",
    "\n",
    "# Get top words unique to wrong predictions (not in top correct words)\n",
    "top_wrong = set([w for w, _ in wrong_word_counts.most_common(50)])\n",
    "top_correct = set([w for w, _ in correct_word_counts.most_common(50)])\n",
    "unique_wrong_words = top_wrong - top_correct\n",
    "\n",
    "print(\"Top 20 words in WRONG predictions:\")\n",
    "print(\"=\" * 80)\n",
    "for word, count in wrong_word_counts.most_common(20):\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "print(f\"\\nTop 20 words unique to WRONG predictions (not in top correct):\")\n",
    "print(\"=\" * 80)\n",
    "unique_wrong_counts = {w: wrong_word_counts[w] for w in unique_wrong_words}\n",
    "for word, count in sorted(unique_wrong_counts.items(), key=lambda x: x[1], reverse=True)[:20]:\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Top words in wrong predictions\n",
    "top_wrong_df = pd.DataFrame(wrong_word_counts.most_common(15), columns=['word', 'count'])\n",
    "top_wrong_df.plot(kind='barh', x='word', y='count', ax=axes[0], legend=False)\n",
    "axes[0].set_title('Top 15 Words in Wrong Predictions')\n",
    "axes[0].set_xlabel('Frequency')\n",
    "\n",
    "# Top words in correct predictions\n",
    "top_correct_df = pd.DataFrame(correct_word_counts.most_common(15), columns=['word', 'count'])\n",
    "top_correct_df.plot(kind='barh', x='word', y='count', ax=axes[1], legend=False, color='green')\n",
    "axes[1].set_title('Top 15 Words in Correct Predictions')\n",
    "axes[1].set_xlabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc983f5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2051e1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"COMPREHENSIVE ERROR ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nAnalysis Mode: {ANALYSIS_MODE.upper()}\")\n",
    "print(f\"Predictions File: {PREDICTIONS_JSON_PATH}\")\n",
    "print(f\"Ground Truth File: {TRUTH_CSV_PATH}\")\n",
    "print(f\"\\nDate: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Correct predictions: {len(df) - len(wrongs)} ({100*(len(df)-len(wrongs))/len(df):.2f}%)\")\n",
    "print(f\"Wrong predictions: {len(wrongs)} ({100*len(wrongs)/len(df):.2f}%)\")\n",
    "\n",
    "if ANALYSIS_MODE == \"binary\":\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"BINARY CLASSIFICATION METRICS\")\n",
    "    print(\"=\" * 80)\n",
    "    fn_count = (wrongs['predicted_label'] == 'NOT_IPV').sum()\n",
    "    fp_count = (wrongs['predicted_label'] == 'IPV').sum()\n",
    "    print(f\"False Negatives (IPV → NOT_IPV): {fn_count} ({100*fn_count/len(wrongs) if len(wrongs) > 0 else 0:.1f}% of errors)\")\n",
    "    print(f\"False Positives (NOT_IPV → IPV): {fp_count} ({100*fp_count/len(wrongs) if len(wrongs) > 0 else 0:.1f}% of errors)\")\n",
    "    \n",
    "elif ANALYSIS_MODE == \"multilabel\":\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"MULTILABEL CLASSIFICATION METRICS\")\n",
    "    print(\"=\" * 80)\n",
    "    for label in [\"emotional\", \"physical\", \"sexual\"]:\n",
    "        correct = (df[f\"{label}_true\"] == df[f\"{label}_pred\"]).sum()\n",
    "        accuracy = 100 * correct / len(df)\n",
    "        errors = (wrongs[f\"{label}_true\"] != wrongs[f\"{label}_pred\"]).sum()\n",
    "        print(f\"{label.capitalize()}: {accuracy:.2f}% accuracy, {errors} errors\")\n",
    "    \n",
    "    print(f\"\\nMost common error pattern: {wrongs['error_pattern'].mode().iloc[0] if len(wrongs) > 0 else 'N/A'}\")\n",
    "    print(\"\\nError pattern distribution:\")\n",
    "    print(wrongs['error_pattern'].value_counts().head(10))\n",
    "\n",
    "if \"type\" in truth.columns and len(wrongs) > 0:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ERRORS BY STATEMENT TYPE\")\n",
    "    print(\"=\" * 80)\n",
    "    wrongs_with_type = wrongs.merge(truth[[\"id\", \"type\"]], on=\"id\", how=\"left\")\n",
    "    type_error_counts = wrongs_with_type.groupby(\"type\").size()\n",
    "    print(type_error_counts)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TEXT CHARACTERISTICS\")\n",
    "print(\"=\" * 80)\n",
    "if len(wrongs) > 0:\n",
    "    print(f\"Avg text length (characters) - Correct: {df[~df['wrong']]['text_length'].mean():.0f}\")\n",
    "    print(f\"Avg text length (characters) - Wrong: {df[df['wrong']]['text_length'].mean():.0f}\")\n",
    "    print(f\"Avg word count - Correct: {df[~df['wrong']]['word_count'].mean():.0f}\")\n",
    "    print(f\"Avg word count - Wrong: {df[df['wrong']]['word_count'].mean():.0f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FILES SAVED\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Wrong predictions CSV: error_analysis_output/wrong_predictions_{ANALYSIS_MODE}_*.csv\")\n",
    "print(f\"Full analysis CSV: error_analysis_output/full_analysis_{ANALYSIS_MODE}_*.csv\")\n",
    "print(\"\\n\" + \"=\" * 80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
