{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "479420e3",
   "metadata": {},
   "source": [
    "# Week 4.\n",
    "**Deliverables**\n",
    "* Refine prompts for Binary & Multitype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1138d41b",
   "metadata": {},
   "source": [
    "## 1. Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce217a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) Zero-Shot — final (no inline JSON examples)\n",
    "prompt_binary_zeroshot = \"\"\"\n",
    "You are analyzing whether a sentence describes Intimate Partner Violence (IPV).\n",
    "\n",
    "Definition:\n",
    "Intimate Partner Violence includes any form of physical, emotional, or sexual harm\n",
    "inflicted by a partner. This may involve control, manipulation, threats, humiliation,\n",
    "or physical aggression.\n",
    "\n",
    "Decide if the following sentence involves IPV or not.\n",
    "\n",
    "Sentence: \"{text}\"\n",
    "\n",
    "Return ONLY one JSON object, enclosed between <json> and </json>.\n",
    "Format: a single key \"label\" with value \"IPV\" or \"NOT_IPV\".\n",
    "Print nothing else.\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "# (2) Few-Shot — final (no inline JSON examples)\n",
    "prompt_binary_fewshot = \"\"\"\n",
    "You are classifying sentences as describing Intimate Partner Violence (IPV) or NOT_IPV.\n",
    "\n",
    "Definition:\n",
    "IPV occurs when one partner harms or controls another physically, emotionally, or sexually.\n",
    "\n",
    "Here are examples (for guidance only):\n",
    "1. \"He pushed me against the wall and shouted that I’m worthless.\" → IPV\n",
    "2. \"She often insults me and forbids me from seeing my friends.\" → IPV\n",
    "3. \"We argued but both apologized and moved on peacefully.\" → NOT_IPV\n",
    "4. \"He surprised me with flowers after work.\" → NOT_IPV\n",
    "\n",
    "Now analyze this sentence:\n",
    "\"{text}\"\n",
    "\n",
    "Return ONLY one JSON object, enclosed between <json> and </json>.\n",
    "Format: {\"label\": \"IPV\"} or {\"label\": \"NOT_IPV\"}.\n",
    "Print nothing else.\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "# (3) Chain-of-Thought — final (no inline JSON examples)\n",
    "prompt_binary_cot = \"\"\"\n",
    "You are reasoning step-by-step to decide if a sentence describes Intimate Partner Violence (IPV).\n",
    "\n",
    "Guidelines:\n",
    "- IPV includes threats, coercion, physical harm, humiliation, or emotional manipulation.\n",
    "- NOT_IPV describes healthy, neutral, or unrelated situations.\n",
    "\n",
    "Think internally (do NOT show your reasoning) about:\n",
    "1. Does the sentence show any behavior that causes harm, fear, or control?\n",
    "2. Is there a partner/relationship context?\n",
    "3. Does it express affection or support instead of harm?\n",
    "\n",
    "After thinking silently, return ONLY one JSON object, enclosed between <json> and </json>.\n",
    "Format: {\"label\": \"IPV\"} or {\"label\": \"NOT_IPV\"}.\n",
    "Print nothing else.\n",
    "\n",
    "Sentence: \"{text}\"\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "# (4) Meta — final (no inline JSON examples)\n",
    "prompt_binary_meta = \"\"\"\n",
    "You are a social-behavioral analyst evaluating sentences for signs of Intimate Partner Violence (IPV).\n",
    "\n",
    "Your objective is to be accurate but cautious.\n",
    "- If the sentence clearly involves harm, coercion, or control → label as IPV.\n",
    "- If the sentence shows affection, neutrality, or uncertainty → label as NOT_IPV.\n",
    "\n",
    "Reflect internally before answering; do NOT print your reasoning.\n",
    "\n",
    "Sentence: \"{text}\"\n",
    "\n",
    "Return ONLY one JSON object, enclosed between <json> and </json>.\n",
    "Format: {\"label\": \"IPV\"} or {\"label\": \"NOT_IPV\"}.\n",
    "Print nothing else.\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "# (5) Self-Consistency — final (no inline JSON examples)\n",
    "prompt_binary_selfconsistency = \"\"\"\n",
    "You will internally evaluate the sentence for Intimate Partner Violence (IPV) multiple times\n",
    "and choose the majority label as your final answer.\n",
    "\n",
    "Guidelines:\n",
    "- IPV → signs of physical, emotional, or sexual harm, threats, or coercion.\n",
    "- NOT_IPV → supportive, neutral, or unrelated content.\n",
    "\n",
    "Do NOT reveal thoughts or votes.\n",
    "\n",
    "Sentence: \"{text}\"\n",
    "\n",
    "Return ONLY one JSON object, enclosed between <json> and </json>.\n",
    "Format: {\"label\": \"IPV\"} or {\"label\": \"NOT_IPV\"}.\n",
    "Print nothing else.\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2ea498",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb692028",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 2. System & Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f65f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from __future__ import annotations\n",
    "from typing import Dict, List, Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4ae826",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILENAMES\n",
    "model_name = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "\n",
    "#Load Model & Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251e43c8",
   "metadata": {},
   "source": [
    "## 3. Prediction Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18ed7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clone from git\n",
    "!git clone https://github.com/zelaneroz/ipvresearch25\n",
    "%cd ipvresearch25/1_LLM_Eval\n",
    "#Load dataset\n",
    "filename = \"../Dataset/617points.csv\"\n",
    "df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36d68b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt dictionaries\n",
    "binary_prompts = {\n",
    "    \"zeroshot\": prompt_binary_zeroshot,\n",
    "    \"fewshot\": prompt_binary_fewshot,\n",
    "    \"cot\": prompt_binary_cot,\n",
    "    \"meta\": prompt_binary_meta,\n",
    "    \"selfconsistency\": prompt_binary_selfconsistency\n",
    "}\n",
    "\n",
    "multilabel_prompts = {\n",
    "    \"zeroshot\": prompt_multilabel_zeroshot,\n",
    "    \"fewshot\": prompt_multilabel_fewshot,\n",
    "    \"cot\": prompt_multilabel_cot,\n",
    "    \"meta\": prompt_multilabel_meta,\n",
    "    \"selfconsistency\": prompt_multilabel_selfconsistency\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ba5ebf",
   "metadata": {},
   "source": [
    "### 3.1 Binary Prediction Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1700430e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_binary_prompts(df, n_samples=3,path):\n",
    "    \"\"\"\n",
    "    Run and test all binary prompt types.\n",
    "    Extracts IPV / NOT_IPV from <json>...</json> blocks\n",
    "    and saves each prompt type's outputs to a separate JSON file.\n",
    "    \"\"\"\n",
    "    import re\n",
    "    import json\n",
    "    from datetime import datetime\n",
    "    from pathlib import Path\n",
    "\n",
    "    df_subset = df.head(n_samples)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    # results_dir = Path(\"../1_LLM_Eval/test_results\")\n",
    "    results_dir=Path(path)\n",
    "    results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(\"Running binary classification tests...\")\n",
    "    print(f\"Number of samples: {len(df_subset)}\")\n",
    "    print(f\"Results will be saved in: {results_dir}\\n\")\n",
    "\n",
    "    for prompt_type, template in binary_prompts.items():\n",
    "        print(f\"Testing prompt type: {prompt_type}\")\n",
    "\n",
    "        records = []\n",
    "\n",
    "        for i, row in df_subset.iterrows():\n",
    "            # Retrieve text input\n",
    "            text = row[\"items\"] if \"items\" in df.columns else str(row.iloc[0])\n",
    "            prompt_text = template.replace(\"{text}\", text)\n",
    "\n",
    "            # Run model\n",
    "            try:\n",
    "                inputs = tokenizer(prompt_text, return_tensors=\"pt\").to(model.device)\n",
    "                output = model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=128,\n",
    "                    temperature=0.0,\n",
    "                    do_sample=False\n",
    "                )\n",
    "                gen_tokens = output[0][inputs[\"input_ids\"].shape[-1]:]\n",
    "                result_text = tokenizer.decode(gen_tokens, skip_special_tokens=True)\n",
    "            except Exception as e:\n",
    "                result_text = f\"ERROR: {e}\"\n",
    "\n",
    "            # Extract label within <json>...</json>\n",
    "            label = None\n",
    "            match = re.search(r\"<json[^>]*>\\s*(.*?)\\s*</json>\", result_text, re.DOTALL | re.IGNORECASE)\n",
    "            if match:\n",
    "                block = match.group(1).strip()\n",
    "                try:\n",
    "                    parsed = json.loads(block)\n",
    "                    if isinstance(parsed, dict):\n",
    "                        label = parsed.get(\"label\") or parsed.get(\"labels\")\n",
    "                    elif isinstance(parsed, list) and len(parsed) > 0:\n",
    "                        label = parsed[0]\n",
    "                    elif isinstance(parsed, str):\n",
    "                        label = parsed.strip()\n",
    "                except json.JSONDecodeError:\n",
    "                    # Handle plain text JSON-like outputs\n",
    "                    if \"NOT_IPV\" in block.upper():\n",
    "                        label = \"NOT_IPV\"\n",
    "                    elif \"IPV\" in block.upper():\n",
    "                        label = \"IPV\"\n",
    "            else:\n",
    "                # Fallback: detect keywords in entire text\n",
    "                if \"NOT_IPV\" in result_text.upper():\n",
    "                    label = \"NOT_IPV\"\n",
    "                elif \"IPV\" in result_text.upper():\n",
    "                    label = \"IPV\"\n",
    "\n",
    "            # Default to UNKNOWN if extraction failed\n",
    "            if label is None:\n",
    "                label = \"UNKNOWN\"\n",
    "\n",
    "            records.append({\n",
    "                \"id\": int(i),\n",
    "                \"prompt_type\": prompt_type,\n",
    "                \"extracted_label\": label,\n",
    "                \"raw_response\": result_text\n",
    "            })\n",
    "\n",
    "        # Save per prompt type\n",
    "        output_path = results_dir / f\"binary_{prompt_type}.json\"\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(records, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "        print(f\"Saved results for '{prompt_type}' to {output_path}\")\n",
    "\n",
    "    print(\"\\nAll binary prompt tests completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4db5db",
   "metadata": {},
   "source": [
    "### 3.2 Multitype Prediction Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528df897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Qwen\n",
    "model_name = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "\n",
    "\n",
    "# ---------- Stage 1: Classification ----------\n",
    "def multitype_predict(sentence, sample_id=None):\n",
    "    prompt = f\"\"\"\n",
    "You are an expert classifier identifying types of Intimate Partner Violence (IPV) from text.\n",
    "\n",
    "Decide which of the following apply (multiple may apply):\n",
    "\n",
    "1. Emotional abuse — verbal or nonverbal behaviors that harm a partner’s self-worth (e.g., humiliation, control, threats, neglect).\n",
    "2. Physical abuse — intentional physical force causing harm or fear (e.g., hitting, pushing, choking, restraining).\n",
    "3. Sexual abuse — unwanted sexual acts or coercion (e.g., pressuring, forcing sex, violating consent).\n",
    "\n",
    "If none apply, set all to 0.\n",
    "\n",
    "Respond **only** with a valid JSON dictionary:\n",
    "{{\n",
    "  \"id\": \"{sample_id or 0}\",\n",
    "  \"emotional\": 0 or 1,\n",
    "  \"physical\": 0 or 1,\n",
    "  \"sexual\": 0 or 1\n",
    "}}\n",
    "\n",
    "Sentence: \"{sentence}\"\n",
    "\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=128,\n",
    "        do_sample=False  # use greedy decoding instead of temperature=0\n",
    "    )\n",
    "    decoded = tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:], skip_special_tokens=True)\n",
    "    try:\n",
    "        return json.loads(decoded)\n",
    "    except:\n",
    "        # Fallback: try to extract JSON if extra text surrounds it\n",
    "        import re\n",
    "        m = re.search(r\"\\{.*\\}\", decoded, re.DOTALL)\n",
    "        return json.loads(m.group()) if m else {\"emotional\": 0, \"physical\": 0, \"sexual\": 0}\n",
    "\n",
    "\n",
    "# ---------- Stage 2: Confidence ----------\n",
    "def logprob_confidence(prompt, generated_text):\n",
    "    # Tokenize prompt + output together\n",
    "    tokens = tokenizer(prompt + generated_text, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokens)\n",
    "        log_probs = torch.nn.functional.log_softmax(outputs.logits, dim=-1)\n",
    "    input_ids = tokens[\"input_ids\"][0]\n",
    "\n",
    "    logp_sum = 0\n",
    "    count = 0\n",
    "    for i in range(1, len(input_ids)):\n",
    "        token_id = input_ids[i]\n",
    "        logp_sum += log_probs[0, i - 1, token_id].item()\n",
    "        count += 1\n",
    "    avg_logp = logp_sum / count\n",
    "    confidence = math.exp(avg_logp)\n",
    "    # Clamp to [0, 1]\n",
    "    return float(max(0.0, min(1.0, confidence)))\n",
    "\n",
    "\n",
    "# ---------- Combined Function ----------\n",
    "def multitype_classify(sentence, sample_id=None):\n",
    "    pred = multitype_predict(sentence, sample_id)\n",
    "\n",
    "    # Use same prompt text from prediction stage for confidence computation\n",
    "    classification_prompt = f\"\"\"\n",
    "You are an expert classifier identifying types of Intimate Partner Violence (IPV) from text.\n",
    "\n",
    "Decide which of the following apply (multiple may apply):\n",
    "\n",
    "1. Emotional abuse — verbal or nonverbal behaviors that harm a partner’s self-worth (e.g., humiliation, control, threats, neglect).\n",
    "2. Physical abuse — intentional physical force causing harm or fear (e.g., hitting, pushing, choking, restraining).\n",
    "3. Sexual abuse — unwanted sexual acts or coercion (e.g., pressuring, forcing sex, violating consent).\n",
    "\n",
    "If none apply, set all to 0.\n",
    "\n",
    "Respond **only** with a valid JSON dictionary:\n",
    "{{\n",
    "  \"id\": \"{sample_id or 0}\",\n",
    "  \"emotional\": 0 or 1,\n",
    "  \"physical\": 0 or 1,\n",
    "  \"sexual\": 0 or 1\n",
    "}}\n",
    "\n",
    "Sentence: \"{sentence}\"\n",
    "\"\"\"\n",
    "    output_str = json.dumps(pred)\n",
    "    conf = logprob_confidence(classification_prompt, output_str)\n",
    "    pred[\"confidence_score\"] = round(conf, 4)\n",
    "    pred[\"id\"] = sample_id or 0\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61de86ab",
   "metadata": {},
   "source": [
    "## 4. Results\n",
    "* Show table of results\n",
    "* Append results to appropriate JSON file\n",
    "* Visualizations \n",
    "\n",
    "* This should utilize `eval_llm_pipeline.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecff4bbc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
